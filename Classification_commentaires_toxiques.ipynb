{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306cdd76",
   "metadata": {},
   "source": [
    "# Classification des Commentaires Toxiques (Simple RNN)\n",
    "\n",
    "Ce notebook implémente un **modèle RNN simple** pour classifier les commentaires comme **toxique ou non toxique**, en utilisant TensorFlow et Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8698ee",
   "metadata": {},
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/mnt/data/train.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1fa50",
   "metadata": {},
   "source": [
    "## 2. Préparation des labels binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Création d'une colonne binaire: 1 si un commentaire est toxique, 0 sinon\n",
    "df['toxic_label'] = (df.iloc[:, 2:].sum(axis=1) > 0).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96914bb",
   "metadata": {},
   "source": [
    "## 3. Prétraitement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e9138",
   "metadata": {},
   "source": [
    "## 4. Tokenization et Séquencement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6463c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['comment_text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['comment_text'])\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "y = df['toxic_label'].values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056dc9b",
   "metadata": {},
   "source": [
    "## 5. Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ac1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc9ce6",
   "metadata": {},
   "source": [
    "## 6. Définition du modèle Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = Input(shape=(100,))\n",
    "embedding = Embedding(input_dim=20000, output_dim=50, input_length=100)(input_layer)\n",
    "rnn = SimpleRNN(32, activation='relu')(embedding)\n",
    "dense = Dense(16, activation='relu')(rnn)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d52823",
   "metadata": {},
   "source": [
    "## 7. Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_data=(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f9e0a",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde du modèle et du tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"/mnt/data/model_toxic_comment_rnn.h5\")\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "import pickle\n",
    "with open(\"/mnt/data/tokenizer.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67daddda",
   "metadata": {},
   "source": [
    "## 9. Évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fbd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3167a3",
   "metadata": {},
   "source": [
    "## 10. Pipeline de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5abfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_comment(text):\n",
    "    text = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=100)\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    return \"Toxique\" if prediction > 0.5 else \"Non Toxique\"\n",
    "\n",
    "# Exemple de test\n",
    "print(predict_comment(\"This is a bad comment!\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
